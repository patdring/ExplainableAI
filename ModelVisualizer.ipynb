{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Jwjl_rQ6BbCz"},"source":["# PyTorch Model Visualizations\n","\n","This notebook contains cells for visualizing custom or pre-trained PyTorch networks."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uiNBwIYDBlLX"},"source":["#### SimpleCNN\n","The code block is defining a simple Convolutional Neural Network (CNN) architecture using the PyTorch nn.Module class.\n","\n","The SimpleCNN class inherits from the nn.Module class and defines the architecture of the CNN. The constructor (__init__) initializes the various layers of the CNN, including two convolutional layers (self.conv1 and self.conv2), two ReLU activation layers (self.relu1 and self.relu2), two max pooling layers (self.pool1 and self.pool2), and two fully connected layers (self.fc1 and self.fc2).\n","\n","The forward method defines the forward pass of the network, where the input tensor x is passed through each layer of the network and transformed by the layer's parameters and activation functions.\n","\n","Finally, an instance of the SimpleCNN class is created and stored in the model variable, which can then be trained using PyTorch's optimization algorithms and datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17bcVHGPTDGG"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# Define the CNN architecture\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n","        self.relu3 = nn.ReLU()\n","        self.fc2 = nn.Linear(64, 43)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu1(x)\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.pool2(x)\n","        x = x.view(-1, 32 * 8 * 8)\n","        x = self.fc1(x)\n","        x = self.relu3(x)\n","        x = self.fc2(x)\n","        return x\n","\n","model = SimpleCNN()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Z7RbdzPGBcIu"},"source":["\n","The code block installs the torchviz and graphviz packages using pip, which are used to visualize the computation graph of a PyTorch model. It then imports the PyTorch library and the make_dot function from the torchviz library.\n","\n","Next, a random input tensor of size (1, 3, 32, 32) is created using torch.randn. The model variable is then used to generate an output tensor by passing the input tensor x through the network.\n","\n","Finally, the make_dot function is used to create a graph visualization of the computation graph of the model. The out tensor and the parameters of the model (obtained using the model.named_parameters() method) are passed as arguments to the make_dot function. The render method is used to save the graph visualization as a PNG image file named \"model_graph_1.png\", which is then displayed using a system-specific image viewer. This visualization can help in understanding the structure of the model and its inputs/outputs, which can be helpful in debugging and optimizing the model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"executionInfo":{"elapsed":9001,"status":"ok","timestamp":1683380796573,"user":{"displayName":"Patrick Döring","userId":"00751407020289025982"},"user_tz":-120},"id":"BLngX8Obl-Jb","outputId":"c803b425-924b-40d1-a23c-b3848f621d01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.0+cu118)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.0.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.12.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (16.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'model_graph_1.png'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["!pip install torchviz graphviz\n","\n","import torch\n","from torchviz import make_dot\n","\n","#model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n","x = torch.randn(1, 3, 32, 32)\n","out = model(x)\n","\n","make_dot(out, params=dict(model.named_parameters())).render(\"model_graph_1\", format=\"png\", view=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SocAnWcnCrmA"},"source":["This code block imports necessary modules and functions from PyTorch and torchview package. A pre-trained PyTorch model is assumed to be defined in the model variable.\n","\n","The draw_graph function from torchview is used to create a visualization of the model's computation graph. The visual_graph attribute of the resulting object is used to save the graph visualization as a PNG image file named \"model_graph2.png\".\n","\n","The matplotlib.pyplot module is imported but not used in this code block."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":5346,"status":"ok","timestamp":1683380801912,"user":{"displayName":"Patrick Döring","userId":"00751407020289025982"},"user_tz":-120},"id":"VFkDBK4RoHA4","outputId":"4a8e89bf-f290-4a30-a2f7-f64b79f79d14"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchview in /usr/local/lib/python3.10/dist-packages (0.2.6)\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'model_graph2.png'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["!pip install torchview\n","import torch\n","import torchvision.models as models\n","from torchsummary import summary\n","import torchvision\n","from torchview import draw_graph\n","import matplotlib.pyplot as plt\n","\n","model_graph = draw_graph(model, input_size=(1,3,32,32), expand_nested=True)\n","visual_graph = model_graph.visual_graph\n","visual_graph.render('model_graph2', format='png')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN3uVaG7hvODUdJAE4pln5e","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
